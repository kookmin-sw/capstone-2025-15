import os
import csv
import MeCab
from kiwipiepy import Kiwi

# í‰ê°€ì…‹ ê²½ë¡œ
TESTSET_DIR = "experiments/tokenizer_comparison/testset"
RESULT_PATH = "experiments/tokenizer_comparison/results.csv"

# Kiwi ì„¤ì • - Semi-BiGRU ê¸°ë°˜ ì„±ëŠ¥ ëª¨ë¸ ì‚¬ìš©
#kiwi = Kiwi()
kiwi = Kiwi(model_type="sbg")
 
def kiwi_analyze(sentence: str) -> list:
    result = kiwi.analyze(sentence, top_n=1)[0][0]
    return [(word, tag) for word, tag, _, _ in result]

# MeCab ì„¤ì •
mecab = MeCab.Tagger('-d /opt/homebrew/lib/mecab/dic/mecab-ko-dic -r /opt/homebrew/etc/mecabrc')

def mecab_analyze(sentence: str) -> list:
    lines = mecab.parse(sentence).split("\n")
    words = []
    for line in lines:
        if line == "EOS" or line == "":
            continue
        try:
            token, feature = line.split("\t")
            pos = feature.split(",")[0]
            words.append((token, pos))
        except:
            print("âš ï¸ Parse error in line:", line)
    return words

# í‰ê°€ ë°ì´í„°ì…‹ ë¡œë“œ
def load_dataset(path):
    dataset = []
    with open(path, encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line: continue
            try:
                answer, exam = line.split("\t")
                answer_word, answer_tag = answer.split("/")
                dataset.append(((answer_word, answer_tag), exam))
            except:
                print(f"âš ï¸ Parse error: {line}")
    return dataset

# í‰ê°€ í•¨ìˆ˜
def evaluate(dataset, analyzer):
    correct, total = 0, 0
    for answer, sentence in dataset:
        tokens = analyzer(sentence)
        if answer in tokens:
            correct += 1
        total += 1
    return correct / total if total else 0

# ë¶„ì„ê¸° ë¦¬ìŠ¤íŠ¸
models = {
    "MeCab": mecab_analyze,
    "Kiwi": kiwi_analyze
}

# í‰ê°€ ì‹¤í–‰ ë° ì €ì¥
results = []
for filename in sorted(os.listdir(TESTSET_DIR)):
    if not filename.endswith(".txt"): continue
    path = os.path.join(TESTSET_DIR, filename)
    dataset = load_dataset(path)
    row = [filename]
    print(f"\nğŸ“‚ {filename}")
    for name, func in models.items():
        acc = evaluate(dataset, func)
        row.append(f"{acc:.3f}")
        print(f"{name}: {acc:.3f}")
    results.append(row)

# CSV ì €ì¥
with open(RESULT_PATH, "w", newline="") as f:
    writer = csv.writer(f)
    writer.writerow(["Testset", *models.keys()])
    writer.writerows(results)
    print(f"\nâœ… í‰ê°€ ê²°ê³¼ ì €ì¥ ì™„ë£Œ â†’ {RESULT_PATH}")


# íŠ¹ì • ë¬¸ì¥ì„ ëŒ€ìƒìœ¼ë¡œ ë‘ ë¶„ì„ê¸°ì˜ ê²°ê³¼ë¥¼ ì¶œë ¥í•´ë³´ì
sample_sentence = "ì €ëŠ” ì ì‹¬ì„ ì•„ì§ ì•ˆ ë¨¹ì–´ì„œ ë°°ê°€ ê³ íŒŒìš”."

print("\nğŸ§ª ë¶„ì„ê¸°ë³„ ê²°ê³¼ ë¹„êµ:")
print(f"ë¬¸ì¥: {sample_sentence}")

# MeCab ê²°ê³¼
mecab_result = mecab_analyze(sample_sentence)
print("\nğŸ“Œ MeCab ê²°ê³¼:")
for token, pos in mecab_result:
    print(f"{token}\t{pos}")

# Kiwi ê²°ê³¼
kiwi_result = kiwi_analyze(sample_sentence)
print("\nğŸ“Œ Kiwi ê²°ê³¼:")
for token, pos in kiwi_result:
    print(f"{token}\t{pos}")
